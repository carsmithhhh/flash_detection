wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: carsmith (carsmith-stanford-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /sdf/home/c/carsmith/flash_reconstruction/flash_detection/wandb/run-20250910_093927-28ozznz1
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run lambda_0.1_poisson_log_part2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/carsmith-stanford-university/transformer_grid
wandb: üöÄ View run at https://wandb.ai/carsmith-stanford-university/transformer_grid/runs/28ozznz1
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
/sdf/home/c/carsmith/flash_reconstruction/flash_detection/run_training.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
  hit_times = torch.tensor(hit_times)
slurmstepd: error: *** JOB 11391182 ON sdfampere040 CANCELLED AT 2025-09-10T09:39:37 ***
